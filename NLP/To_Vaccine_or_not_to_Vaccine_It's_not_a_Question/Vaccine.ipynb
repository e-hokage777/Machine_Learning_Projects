{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8d0b6ba9-f744-4430-a0b0-b5f83e13eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3087da1e-e6fc-4e93-b0ad-d061ec1d13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the data\n",
    "data_path = \"x__data\"\n",
    "df_train = pd.read_csv(f\"{data_path}/train.csv\")\n",
    "df_test = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "sample_submission = pd.read_csv(f\"{data_path}/samplesubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "415c453f-2e85-488f-a070-0865f0369fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>safe_text</th>\n",
       "      <th>label</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL1KWCMY</td>\n",
       "      <td>Me &amp;amp; The Big Homie meanboy3000 #MEANBOY #M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E3303EME</td>\n",
       "      <td>I'm 100% thinking of devoting my career to pro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M4IVFSMS</td>\n",
       "      <td>#whatcausesautism VACCINES, DO NOT VACCINATE Y...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1DR6ROZ4</td>\n",
       "      <td>I mean if they immunize my kid with something ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J77ENIIE</td>\n",
       "      <td>Thanks to &lt;user&gt; Catch me performing at La Nui...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                          safe_text  label  \\\n",
       "0  CL1KWCMY  Me &amp; The Big Homie meanboy3000 #MEANBOY #M...    0.0   \n",
       "1  E3303EME  I'm 100% thinking of devoting my career to pro...    1.0   \n",
       "2  M4IVFSMS  #whatcausesautism VACCINES, DO NOT VACCINATE Y...   -1.0   \n",
       "3  1DR6ROZ4  I mean if they immunize my kid with something ...   -1.0   \n",
       "4  J77ENIIE  Thanks to <user> Catch me performing at La Nui...    0.0   \n",
       "\n",
       "   agreement  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d3613a7d-d526-4c81-be0b-ab82dd7e7311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id     0\n",
       "safe_text    0\n",
       "label        1\n",
       "agreement    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking for missing\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "32e14424-354f-47a2-a7dd-826088b2b86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreement\n",
       "1.000000    5866\n",
       "0.666667    3894\n",
       "0.333333     239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking the keyword column\n",
    "df_train[\"agreement\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "23e36651-2e11-4a03-9e6a-610852a43901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 0.000000    4908\n",
       " 1.000000    4053\n",
       "-1.000000    1038\n",
       " 0.666667       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## looking at the number of samples per class\n",
    "df_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a842a99-2568-4946-9af8-949bb387c8d9",
   "metadata": {},
   "source": [
    "#### Choosing to train only only columns that have above `60%` agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "90fc0ee4-2dc3-43de-9c84-61bb713f66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train[\"agreement\"] > 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a28b781e-a5f4-4394-a929-e162d6cbf73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9426,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"safe_text\"].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a8ddf57a-fa40-48cf-adb1-f46fdb557b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9760, 4)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448fa46f-191e-4948-8714-e78710031c40",
   "metadata": {},
   "source": [
    "##### Removing the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "51e24042-d3b2-4966-b2a4-a080ebed0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop_duplicates(subset=\"safe_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9c98d88b-b3d4-4874-b58b-9c224774758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9426, 4)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sanity check\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c82b68-dace-4e33-8597-36ffeb05a6dc",
   "metadata": {},
   "source": [
    "##### Looking at a random text sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "753b99f2-ce5a-4ec4-a972-483736a1a456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Indiana State Department of Health has issued some immunization changes for the 2014-15... <url> <user>',\n",
       "       'Every cause needs a champion - Dr Lucas Otieno. We see this every day in our amazing health workers. #vaccineswork <user>',\n",
       "       '#SuperStarSundays thepalace_nj #MMR @ The Palace <url>',\n",
       "       'Measles continues to spread in Orange County <url>',\n",
       "       '“<user> Georgia confirms its first #measles case since 2012 - an infant from outside the country <url> nopeee'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(n=5)[\"safe_text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "789a3db4-9661-45e4-a9b1-b178b7eeddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for cleaning function\n",
    "## - remove urls\n",
    "## - remove # tags\n",
    "## - remove html special characters eg &amp;\n",
    "## - remove @text\n",
    "## - remove [01:04 UTC]\n",
    "## - strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2d60ad2e-12cd-4956-9e59-bc08f066ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "## function to preprocessing of text\n",
    "def process_text(text):\n",
    "    ## patterns to remove\n",
    "    rem_pat_1 = \"([@]|https?:)\\S*\"\n",
    "    rem_pat_2 = \"&\\S+;\"\n",
    "    rem_pat_3 = \"\\[\\d+:\\d+.+\\]\" ## removing timestamp. eg. [01:04 UTC]\n",
    "    rem_pat_4 = \"[\\-_.+#]\" ## to remove symbols (make sure to bring last to avoid affecting first two patterns)\n",
    "    rem_pat_5 = \"<.*>\"\n",
    "    combined_rem_pat = f\"({rem_pat_1})|({rem_pat_2})|({rem_pat_3})|({rem_pat_4})|({rem_pat_5})\"\n",
    "\n",
    "    text = re.sub(combined_rem_pat, \"\", text) ## removing text that match patterns\n",
    "    text = text.strip() ## removing trailing white spaces\n",
    "    text = text.lower() ## lowercasing\n",
    "\n",
    "    return text\n",
    "\n",
    "## function for tokenizing of string\n",
    "def tokenize(text):\n",
    "    return re.split(\"\\s+\", text)\n",
    "\n",
    "## function to remove stop words\n",
    "def remove_stopwords(token_list):\n",
    "    l = []\n",
    "    for word in token_list:\n",
    "        if word not in stopwords:\n",
    "            l.append(word)\n",
    "    return l\n",
    "\n",
    "def full_text_process(text):\n",
    "    text = process_text(text)\n",
    "    # text = tokenize(text)\n",
    "    # text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6ea6ad0f-f9d9-4617-a111-eeb636216b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating datatransformers\n",
    "class GloveVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, filepath=\".\", encoding=\"utf-8\"):\n",
    "        self.filepath = filepath\n",
    "        self.encoding = encoding\n",
    "\n",
    "    def fitX(self, X):\n",
    "        self.unique_words = set()\n",
    "        self.vectors = []\n",
    "        self.word2idx = {}\n",
    "\n",
    "        ## getting unique words\n",
    "        for text in X:\n",
    "            self.unique_words |= set(text.split())\n",
    "\n",
    "        ## builing word to index dictionary and vector matrix\n",
    "        idx = 0\n",
    "        with open(self.filepath, encoding=self.encoding) as  file:\n",
    "            for line in file:\n",
    "                line = line.split()\n",
    "                word = line[0]\n",
    "                if word in self.unique_words:\n",
    "                    self.word2idx[word] = idx\n",
    "                    self.vectors.append(line[1:])\n",
    "                    idx+=1\n",
    "\n",
    "        self.vectors = np.array(self.vectors, dtype=np.float32)\n",
    "\n",
    "    def fitY(self, y):\n",
    "        ## creating integer labels for each category\n",
    "        unique = {x for x in y}\n",
    "        self.label2int = dict([(v,i) for i,v in enumerate(unique)])\n",
    "\n",
    "\n",
    "    def transformX(self, X):\n",
    "        N = len(X)\n",
    "        transformed_x = np.zeros((N, self.vectors.shape[1]), dtype=np.float32)\n",
    "        for i in range(N):\n",
    "            mat = []\n",
    "            line = X[i].lower().split()\n",
    "            for word in line:\n",
    "                if word in self.word2idx:\n",
    "                    mat.append(self.vectors[self.word2idx[word]])\n",
    "\n",
    "            if len(mat) > 0: transformed_x[i] = np.mean(mat, axis=0)\n",
    "            else: print(f\"Sentence at index:{i} has no word in the vector dictionary\")\n",
    "\n",
    "        return np.array(transformed_x)\n",
    "\n",
    "    def transformY(self, y):\n",
    "        return np.array([self.label2int[word] for word in y])\n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.fitX(X)\n",
    "\n",
    "        if y is not None: self.fitY(y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if y is not None: return self.transformX(X), self.transformY(y)\n",
    "        else: return self.transformX(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X,y)\n",
    "        return self.transform(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1c2f0e9d-009b-4bff-8c5f-9506b8a01653",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the training and testing processed data\n",
    "## train\n",
    "train_text = df_train[\"safe_text\"].apply(lambda x: full_text_process(x)).values\n",
    "train_target = df_train[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "02a21d6a-3a34-4248-8715-eec82f334e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an nonimmunized child must be treated differently by docneed to recognize that deadly vaccine preventable diseases are possible vaccines'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6fde0bbf-14b8-4f6f-8ca2-85790555b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_text, train_target, test_size=0.3, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e6bb7d75-e45d-461f-8aba-6f68d4602d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"../../../Machine_Learning_With_Python/NLP_LEARN/data/glove6B/glove.6B.50d.txt\"\n",
    "vectorizer = GloveVectorizer(glove_path, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78516039-f917-46fe-b680-a41e46720430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GloveVectorizer(filepath=&#x27;../../../Machine_Learning_With_Python/NLP_LEARN/data/glove6B/glove.6B.50d.txt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GloveVectorizer</label><div class=\"sk-toggleable__content\"><pre>GloveVectorizer(filepath=&#x27;../../../Machine_Learning_With_Python/NLP_LEARN/data/glove6B/glove.6B.50d.txt&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GloveVectorizer(filepath='../../../Machine_Learning_With_Python/NLP_LEARN/data/glove6B/glove.6B.50d.txt')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "af4ca60e-c80a-4e84-9e05-e1d0a423969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence at index:17 has no word in the vector dictionary\n",
      "Sentence at index:42 has no word in the vector dictionary\n",
      "Sentence at index:71 has no word in the vector dictionary\n",
      "Sentence at index:109 has no word in the vector dictionary\n",
      "Sentence at index:112 has no word in the vector dictionary\n",
      "Sentence at index:153 has no word in the vector dictionary\n",
      "Sentence at index:175 has no word in the vector dictionary\n",
      "Sentence at index:234 has no word in the vector dictionary\n",
      "Sentence at index:252 has no word in the vector dictionary\n",
      "Sentence at index:266 has no word in the vector dictionary\n",
      "Sentence at index:366 has no word in the vector dictionary\n",
      "Sentence at index:426 has no word in the vector dictionary\n",
      "Sentence at index:441 has no word in the vector dictionary\n",
      "Sentence at index:480 has no word in the vector dictionary\n",
      "Sentence at index:483 has no word in the vector dictionary\n",
      "Sentence at index:674 has no word in the vector dictionary\n",
      "Sentence at index:722 has no word in the vector dictionary\n",
      "Sentence at index:739 has no word in the vector dictionary\n",
      "Sentence at index:743 has no word in the vector dictionary\n",
      "Sentence at index:750 has no word in the vector dictionary\n",
      "Sentence at index:790 has no word in the vector dictionary\n",
      "Sentence at index:797 has no word in the vector dictionary\n",
      "Sentence at index:809 has no word in the vector dictionary\n",
      "Sentence at index:840 has no word in the vector dictionary\n",
      "Sentence at index:911 has no word in the vector dictionary\n",
      "Sentence at index:969 has no word in the vector dictionary\n",
      "Sentence at index:992 has no word in the vector dictionary\n",
      "Sentence at index:1060 has no word in the vector dictionary\n",
      "Sentence at index:1081 has no word in the vector dictionary\n",
      "Sentence at index:1113 has no word in the vector dictionary\n",
      "Sentence at index:1148 has no word in the vector dictionary\n",
      "Sentence at index:1205 has no word in the vector dictionary\n",
      "Sentence at index:1245 has no word in the vector dictionary\n",
      "Sentence at index:1264 has no word in the vector dictionary\n",
      "Sentence at index:1281 has no word in the vector dictionary\n",
      "Sentence at index:1321 has no word in the vector dictionary\n",
      "Sentence at index:1474 has no word in the vector dictionary\n",
      "Sentence at index:1631 has no word in the vector dictionary\n",
      "Sentence at index:1638 has no word in the vector dictionary\n",
      "Sentence at index:1713 has no word in the vector dictionary\n",
      "Sentence at index:1717 has no word in the vector dictionary\n",
      "Sentence at index:1759 has no word in the vector dictionary\n",
      "Sentence at index:1841 has no word in the vector dictionary\n",
      "Sentence at index:1849 has no word in the vector dictionary\n",
      "Sentence at index:1862 has no word in the vector dictionary\n",
      "Sentence at index:1864 has no word in the vector dictionary\n",
      "Sentence at index:1931 has no word in the vector dictionary\n",
      "Sentence at index:1988 has no word in the vector dictionary\n",
      "Sentence at index:2016 has no word in the vector dictionary\n",
      "Sentence at index:2126 has no word in the vector dictionary\n",
      "Sentence at index:2216 has no word in the vector dictionary\n",
      "Sentence at index:2276 has no word in the vector dictionary\n",
      "Sentence at index:2315 has no word in the vector dictionary\n",
      "Sentence at index:2356 has no word in the vector dictionary\n",
      "Sentence at index:2419 has no word in the vector dictionary\n",
      "Sentence at index:2529 has no word in the vector dictionary\n",
      "Sentence at index:2569 has no word in the vector dictionary\n",
      "Sentence at index:2573 has no word in the vector dictionary\n",
      "Sentence at index:2595 has no word in the vector dictionary\n",
      "Sentence at index:2675 has no word in the vector dictionary\n",
      "Sentence at index:2742 has no word in the vector dictionary\n",
      "Sentence at index:2784 has no word in the vector dictionary\n",
      "Sentence at index:2924 has no word in the vector dictionary\n",
      "Sentence at index:2946 has no word in the vector dictionary\n",
      "Sentence at index:2948 has no word in the vector dictionary\n",
      "Sentence at index:2981 has no word in the vector dictionary\n",
      "Sentence at index:2988 has no word in the vector dictionary\n",
      "Sentence at index:3004 has no word in the vector dictionary\n",
      "Sentence at index:3018 has no word in the vector dictionary\n",
      "Sentence at index:3038 has no word in the vector dictionary\n",
      "Sentence at index:3045 has no word in the vector dictionary\n",
      "Sentence at index:3075 has no word in the vector dictionary\n",
      "Sentence at index:3119 has no word in the vector dictionary\n",
      "Sentence at index:3202 has no word in the vector dictionary\n",
      "Sentence at index:3209 has no word in the vector dictionary\n",
      "Sentence at index:3217 has no word in the vector dictionary\n",
      "Sentence at index:3275 has no word in the vector dictionary\n",
      "Sentence at index:3313 has no word in the vector dictionary\n",
      "Sentence at index:3334 has no word in the vector dictionary\n",
      "Sentence at index:3350 has no word in the vector dictionary\n",
      "Sentence at index:3370 has no word in the vector dictionary\n",
      "Sentence at index:3372 has no word in the vector dictionary\n",
      "Sentence at index:3422 has no word in the vector dictionary\n",
      "Sentence at index:3427 has no word in the vector dictionary\n",
      "Sentence at index:3471 has no word in the vector dictionary\n",
      "Sentence at index:3565 has no word in the vector dictionary\n",
      "Sentence at index:3572 has no word in the vector dictionary\n",
      "Sentence at index:3578 has no word in the vector dictionary\n",
      "Sentence at index:3621 has no word in the vector dictionary\n",
      "Sentence at index:3648 has no word in the vector dictionary\n",
      "Sentence at index:3707 has no word in the vector dictionary\n",
      "Sentence at index:3727 has no word in the vector dictionary\n",
      "Sentence at index:3738 has no word in the vector dictionary\n",
      "Sentence at index:3757 has no word in the vector dictionary\n",
      "Sentence at index:3838 has no word in the vector dictionary\n",
      "Sentence at index:3898 has no word in the vector dictionary\n",
      "Sentence at index:3900 has no word in the vector dictionary\n",
      "Sentence at index:3910 has no word in the vector dictionary\n",
      "Sentence at index:3935 has no word in the vector dictionary\n",
      "Sentence at index:4048 has no word in the vector dictionary\n",
      "Sentence at index:4055 has no word in the vector dictionary\n",
      "Sentence at index:4085 has no word in the vector dictionary\n",
      "Sentence at index:4112 has no word in the vector dictionary\n",
      "Sentence at index:4216 has no word in the vector dictionary\n",
      "Sentence at index:4232 has no word in the vector dictionary\n",
      "Sentence at index:4240 has no word in the vector dictionary\n",
      "Sentence at index:4254 has no word in the vector dictionary\n",
      "Sentence at index:4283 has no word in the vector dictionary\n",
      "Sentence at index:4315 has no word in the vector dictionary\n",
      "Sentence at index:4336 has no word in the vector dictionary\n",
      "Sentence at index:4390 has no word in the vector dictionary\n",
      "Sentence at index:4508 has no word in the vector dictionary\n",
      "Sentence at index:4513 has no word in the vector dictionary\n",
      "Sentence at index:4555 has no word in the vector dictionary\n",
      "Sentence at index:4658 has no word in the vector dictionary\n",
      "Sentence at index:4751 has no word in the vector dictionary\n",
      "Sentence at index:4763 has no word in the vector dictionary\n",
      "Sentence at index:4814 has no word in the vector dictionary\n",
      "Sentence at index:4816 has no word in the vector dictionary\n",
      "Sentence at index:4850 has no word in the vector dictionary\n",
      "Sentence at index:4903 has no word in the vector dictionary\n",
      "Sentence at index:4995 has no word in the vector dictionary\n",
      "Sentence at index:5012 has no word in the vector dictionary\n",
      "Sentence at index:5060 has no word in the vector dictionary\n",
      "Sentence at index:5135 has no word in the vector dictionary\n",
      "Sentence at index:5222 has no word in the vector dictionary\n",
      "Sentence at index:5254 has no word in the vector dictionary\n",
      "Sentence at index:5419 has no word in the vector dictionary\n",
      "Sentence at index:5429 has no word in the vector dictionary\n",
      "Sentence at index:5517 has no word in the vector dictionary\n",
      "Sentence at index:5561 has no word in the vector dictionary\n",
      "Sentence at index:5563 has no word in the vector dictionary\n",
      "Sentence at index:5637 has no word in the vector dictionary\n",
      "Sentence at index:5715 has no word in the vector dictionary\n",
      "Sentence at index:5734 has no word in the vector dictionary\n",
      "Sentence at index:5738 has no word in the vector dictionary\n",
      "Sentence at index:5785 has no word in the vector dictionary\n",
      "Sentence at index:5894 has no word in the vector dictionary\n",
      "Sentence at index:5902 has no word in the vector dictionary\n",
      "Sentence at index:6136 has no word in the vector dictionary\n",
      "Sentence at index:6271 has no word in the vector dictionary\n",
      "Sentence at index:6300 has no word in the vector dictionary\n",
      "Sentence at index:6447 has no word in the vector dictionary\n",
      "Sentence at index:6481 has no word in the vector dictionary\n",
      "Sentence at index:6483 has no word in the vector dictionary\n",
      "Sentence at index:6512 has no word in the vector dictionary\n",
      "Sentence at index:6517 has no word in the vector dictionary\n",
      "Sentence at index:6818 has no word in the vector dictionary\n",
      "Sentence at index:6842 has no word in the vector dictionary\n",
      "Sentence at index:6849 has no word in the vector dictionary\n",
      "Sentence at index:6859 has no word in the vector dictionary\n",
      "Sentence at index:6874 has no word in the vector dictionary\n",
      "Sentence at index:6920 has no word in the vector dictionary\n",
      "Sentence at index:6944 has no word in the vector dictionary\n",
      "Sentence at index:7039 has no word in the vector dictionary\n",
      "Sentence at index:7066 has no word in the vector dictionary\n",
      "Sentence at index:7109 has no word in the vector dictionary\n",
      "Sentence at index:7195 has no word in the vector dictionary\n",
      "Sentence at index:7206 has no word in the vector dictionary\n",
      "Sentence at index:7210 has no word in the vector dictionary\n",
      "Sentence at index:7222 has no word in the vector dictionary\n",
      "Sentence at index:7239 has no word in the vector dictionary\n",
      "Sentence at index:7277 has no word in the vector dictionary\n",
      "Sentence at index:7278 has no word in the vector dictionary\n",
      "Sentence at index:7337 has no word in the vector dictionary\n",
      "Sentence at index:7342 has no word in the vector dictionary\n",
      "Sentence at index:7417 has no word in the vector dictionary\n",
      "Sentence at index:7435 has no word in the vector dictionary\n",
      "Sentence at index:7454 has no word in the vector dictionary\n",
      "Sentence at index:7524 has no word in the vector dictionary\n",
      "Sentence at index:7710 has no word in the vector dictionary\n",
      "Sentence at index:7720 has no word in the vector dictionary\n",
      "Sentence at index:7724 has no word in the vector dictionary\n",
      "Sentence at index:7782 has no word in the vector dictionary\n",
      "Sentence at index:7793 has no word in the vector dictionary\n",
      "Sentence at index:7798 has no word in the vector dictionary\n",
      "Sentence at index:7937 has no word in the vector dictionary\n",
      "Sentence at index:8019 has no word in the vector dictionary\n",
      "Sentence at index:8042 has no word in the vector dictionary\n",
      "Sentence at index:8107 has no word in the vector dictionary\n",
      "Sentence at index:8131 has no word in the vector dictionary\n",
      "Sentence at index:8137 has no word in the vector dictionary\n",
      "Sentence at index:8225 has no word in the vector dictionary\n",
      "Sentence at index:8226 has no word in the vector dictionary\n",
      "Sentence at index:8297 has no word in the vector dictionary\n",
      "Sentence at index:8363 has no word in the vector dictionary\n",
      "Sentence at index:8379 has no word in the vector dictionary\n",
      "Sentence at index:8445 has no word in the vector dictionary\n",
      "Sentence at index:8530 has no word in the vector dictionary\n",
      "Sentence at index:8552 has no word in the vector dictionary\n",
      "Sentence at index:8639 has no word in the vector dictionary\n",
      "Sentence at index:8678 has no word in the vector dictionary\n",
      "Sentence at index:8753 has no word in the vector dictionary\n",
      "Sentence at index:8778 has no word in the vector dictionary\n",
      "Sentence at index:8800 has no word in the vector dictionary\n",
      "Sentence at index:8829 has no word in the vector dictionary\n",
      "Sentence at index:8844 has no word in the vector dictionary\n",
      "Sentence at index:8881 has no word in the vector dictionary\n",
      "Sentence at index:8896 has no word in the vector dictionary\n",
      "Sentence at index:8928 has no word in the vector dictionary\n",
      "Sentence at index:8954 has no word in the vector dictionary\n",
      "Sentence at index:9000 has no word in the vector dictionary\n",
      "Sentence at index:9017 has no word in the vector dictionary\n",
      "Sentence at index:9053 has no word in the vector dictionary\n",
      "Sentence at index:9055 has no word in the vector dictionary\n",
      "Sentence at index:9128 has no word in the vector dictionary\n",
      "Sentence at index:9141 has no word in the vector dictionary\n",
      "Sentence at index:9221 has no word in the vector dictionary\n",
      "Sentence at index:9258 has no word in the vector dictionary\n",
      "Sentence at index:9267 has no word in the vector dictionary\n",
      "Sentence at index:9298 has no word in the vector dictionary\n",
      "Sentence at index:9311 has no word in the vector dictionary\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.transform(train_text)\n",
    "y = train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2299f-e593-4283-a0cb-0af5e29438bb",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9e5ad016-e2b5-4c32-a1ae-38076883487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4477c-46b0-4362-8155-02a0cbcb34de",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e34dcfd5-78ed-461e-ac6d-b3af50f62588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START max_depth=8, n_estimators=200...............................\n",
      "[CV 1/5; 1/4] END max_depth=8, n_estimators=200;, score=-0.591 total time= 2.1min\n",
      "[CV 2/5; 1/4] START max_depth=8, n_estimators=200...............................\n",
      "[CV 2/5; 1/4] END max_depth=8, n_estimators=200;, score=-0.590 total time= 2.3min\n",
      "[CV 3/5; 1/4] START max_depth=8, n_estimators=200...............................\n",
      "[CV 3/5; 1/4] END max_depth=8, n_estimators=200;, score=-0.584 total time= 2.2min\n",
      "[CV 4/5; 1/4] START max_depth=8, n_estimators=200...............................\n",
      "[CV 4/5; 1/4] END max_depth=8, n_estimators=200;, score=-0.582 total time= 2.1min\n",
      "[CV 5/5; 1/4] START max_depth=8, n_estimators=200...............................\n",
      "[CV 5/5; 1/4] END max_depth=8, n_estimators=200;, score=-0.593 total time= 2.2min\n",
      "[CV 1/5; 2/4] START max_depth=8, n_estimators=300...............................\n",
      "[CV 1/5; 2/4] END max_depth=8, n_estimators=300;, score=-0.590 total time= 3.7min\n",
      "[CV 2/5; 2/4] START max_depth=8, n_estimators=300...............................\n",
      "[CV 2/5; 2/4] END max_depth=8, n_estimators=300;, score=-0.591 total time= 3.1min\n",
      "[CV 3/5; 2/4] START max_depth=8, n_estimators=300...............................\n",
      "[CV 3/5; 2/4] END max_depth=8, n_estimators=300;, score=-0.584 total time= 3.0min\n",
      "[CV 4/5; 2/4] START max_depth=8, n_estimators=300...............................\n",
      "[CV 4/5; 2/4] END max_depth=8, n_estimators=300;, score=-0.581 total time= 3.3min\n",
      "[CV 5/5; 2/4] START max_depth=8, n_estimators=300...............................\n",
      "[CV 5/5; 2/4] END max_depth=8, n_estimators=300;, score=-0.591 total time= 3.0min\n",
      "[CV 1/5; 3/4] START max_depth=10, n_estimators=200..............................\n",
      "[CV 1/5; 3/4] END max_depth=10, n_estimators=200;, score=-0.588 total time= 2.6min\n",
      "[CV 2/5; 3/4] START max_depth=10, n_estimators=200..............................\n",
      "[CV 2/5; 3/4] END max_depth=10, n_estimators=200;, score=-0.588 total time= 2.4min\n",
      "[CV 3/5; 3/4] START max_depth=10, n_estimators=200..............................\n",
      "[CV 3/5; 3/4] END max_depth=10, n_estimators=200;, score=-0.580 total time= 3.0min\n",
      "[CV 4/5; 3/4] START max_depth=10, n_estimators=200..............................\n",
      "[CV 4/5; 3/4] END max_depth=10, n_estimators=200;, score=-0.580 total time= 2.7min\n",
      "[CV 5/5; 3/4] START max_depth=10, n_estimators=200..............................\n",
      "[CV 5/5; 3/4] END max_depth=10, n_estimators=200;, score=-0.590 total time= 2.3min\n",
      "[CV 1/5; 4/4] START max_depth=10, n_estimators=300..............................\n",
      "[CV 1/5; 4/4] END max_depth=10, n_estimators=300;, score=-0.588 total time= 3.8min\n",
      "[CV 2/5; 4/4] START max_depth=10, n_estimators=300..............................\n",
      "[CV 2/5; 4/4] END max_depth=10, n_estimators=300;, score=-0.589 total time= 3.8min\n",
      "[CV 3/5; 4/4] START max_depth=10, n_estimators=300..............................\n",
      "[CV 3/5; 4/4] END max_depth=10, n_estimators=300;, score=-0.581 total time= 3.8min\n",
      "[CV 4/5; 4/4] START max_depth=10, n_estimators=300..............................\n",
      "[CV 4/5; 4/4] END max_depth=10, n_estimators=300;, score=-0.578 total time= 4.2min\n",
      "[CV 5/5; 4/4] START max_depth=10, n_estimators=300..............................\n",
      "[CV 5/5; 4/4] END max_depth=10, n_estimators=300;, score=-0.589 total time= 4.7min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [8, 10], &#x27;n_estimators&#x27;: [200, 300]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [8, 10], &#x27;n_estimators&#x27;: [200, 300]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [8, 10], 'n_estimators': [200, 300]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=10)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": [200, 300],\n",
    "    \"max_depth\": [ 8, 10],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestRegressor(), params, cv=kf, scoring=\"neg_root_mean_squared_error\", verbose=10)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8b1928f7-2b28-48ac-bac0-f7d561c7e113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.5849319372968924\n",
      "Best Parameters: {'max_depth': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\", grid.best_score_)\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6c7e4-77b2-44ca-8eb7-2c9d6f779a1e",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "befa604f-f5c0-412d-85ea-437749785116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START max_depth=16, n_estimators=600..............................\n",
      "[CV 1/5; 1/4] END max_depth=16, n_estimators=600;, score=-0.674 total time=  20.7s\n",
      "[CV 2/5; 1/4] START max_depth=16, n_estimators=600..............................\n",
      "[CV 2/5; 1/4] END max_depth=16, n_estimators=600;, score=-0.699 total time=  19.0s\n",
      "[CV 3/5; 1/4] START max_depth=16, n_estimators=600..............................\n",
      "[CV 3/5; 1/4] END max_depth=16, n_estimators=600;, score=-0.673 total time=  18.8s\n",
      "[CV 4/5; 1/4] START max_depth=16, n_estimators=600..............................\n",
      "[CV 4/5; 1/4] END max_depth=16, n_estimators=600;, score=-0.674 total time=  18.5s\n",
      "[CV 5/5; 1/4] START max_depth=16, n_estimators=600..............................\n",
      "[CV 5/5; 1/4] END max_depth=16, n_estimators=600;, score=-0.693 total time=  17.8s\n",
      "[CV 1/5; 2/4] START max_depth=16, n_estimators=700..............................\n",
      "[CV 1/5; 2/4] END max_depth=16, n_estimators=700;, score=-0.686 total time=  22.8s\n",
      "[CV 2/5; 2/4] START max_depth=16, n_estimators=700..............................\n",
      "[CV 2/5; 2/4] END max_depth=16, n_estimators=700;, score=-0.692 total time=  22.0s\n",
      "[CV 3/5; 2/4] START max_depth=16, n_estimators=700..............................\n",
      "[CV 3/5; 2/4] END max_depth=16, n_estimators=700;, score=-0.672 total time=  21.8s\n",
      "[CV 4/5; 2/4] START max_depth=16, n_estimators=700..............................\n",
      "[CV 4/5; 2/4] END max_depth=16, n_estimators=700;, score=-0.679 total time=  21.8s\n",
      "[CV 5/5; 2/4] START max_depth=16, n_estimators=700..............................\n",
      "[CV 5/5; 2/4] END max_depth=16, n_estimators=700;, score=-0.697 total time=  21.7s\n",
      "[CV 1/5; 3/4] START max_depth=18, n_estimators=600..............................\n",
      "[CV 1/5; 3/4] END max_depth=18, n_estimators=600;, score=-0.678 total time=  22.7s\n",
      "[CV 2/5; 3/4] START max_depth=18, n_estimators=600..............................\n",
      "[CV 2/5; 3/4] END max_depth=18, n_estimators=600;, score=-0.698 total time=  22.4s\n",
      "[CV 3/5; 3/4] START max_depth=18, n_estimators=600..............................\n",
      "[CV 3/5; 3/4] END max_depth=18, n_estimators=600;, score=-0.675 total time=  25.1s\n",
      "[CV 4/5; 3/4] START max_depth=18, n_estimators=600..............................\n",
      "[CV 4/5; 3/4] END max_depth=18, n_estimators=600;, score=-0.680 total time=  22.4s\n",
      "[CV 5/5; 3/4] START max_depth=18, n_estimators=600..............................\n",
      "[CV 5/5; 3/4] END max_depth=18, n_estimators=600;, score=-0.700 total time=  22.6s\n",
      "[CV 1/5; 4/4] START max_depth=18, n_estimators=700..............................\n",
      "[CV 1/5; 4/4] END max_depth=18, n_estimators=700;, score=-0.682 total time=  26.5s\n",
      "[CV 2/5; 4/4] START max_depth=18, n_estimators=700..............................\n",
      "[CV 2/5; 4/4] END max_depth=18, n_estimators=700;, score=-0.700 total time=  26.4s\n",
      "[CV 3/5; 4/4] START max_depth=18, n_estimators=700..............................\n",
      "[CV 3/5; 4/4] END max_depth=18, n_estimators=700;, score=-0.669 total time=  26.1s\n",
      "[CV 4/5; 4/4] START max_depth=18, n_estimators=700..............................\n",
      "[CV 4/5; 4/4] END max_depth=18, n_estimators=700;, score=-0.681 total time=  25.9s\n",
      "[CV 5/5; 4/4] START max_depth=18, n_estimators=700..............................\n",
      "[CV 5/5; 4/4] END max_depth=18, n_estimators=700;, score=-0.699 total time=  25.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=ExtraTreesClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [16, 18], &#x27;n_estimators&#x27;: [600, 700]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=ExtraTreesClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [16, 18], &#x27;n_estimators&#x27;: [600, 700]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=ExtraTreesClassifier(),\n",
       "             param_grid={'max_depth': [16, 18], 'n_estimators': [600, 700]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=10)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": [600, 700],\n",
    "    \"max_depth\": [16, 18],\n",
    "}\n",
    "\n",
    "grid_ex = GridSearchCV(ExtraTreesClassifier(), params, cv=kf, scoring=\"neg_root_mean_squared_error\", verbose=10)\n",
    "grid_ex.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc082f5e-2bcc-4e14-aa9b-71dde072ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7998154448262861\n",
      "Best Parameters: {'max_depth': 18, 'n_estimators': 600}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\", grid.best_score_)\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7275b-8afa-4b98-ae7e-033cb55b67df",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9e16ac0f-a3f2-466d-a00c-8019d852f1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START learning_rate=0.05, max_depth=6, n_estimators=200..........\n",
      "[CV 1/5; 1/12] END learning_rate=0.05, max_depth=6, n_estimators=200;, score=0.805 total time=   3.1s\n",
      "[CV 2/5; 1/12] START learning_rate=0.05, max_depth=6, n_estimators=200..........\n",
      "[CV 2/5; 1/12] END learning_rate=0.05, max_depth=6, n_estimators=200;, score=0.809 total time=   3.0s\n",
      "[CV 3/5; 1/12] START learning_rate=0.05, max_depth=6, n_estimators=200..........\n",
      "[CV 3/5; 1/12] END learning_rate=0.05, max_depth=6, n_estimators=200;, score=0.798 total time=   2.6s\n",
      "[CV 4/5; 1/12] START learning_rate=0.05, max_depth=6, n_estimators=200..........\n",
      "[CV 4/5; 1/12] END learning_rate=0.05, max_depth=6, n_estimators=200;, score=0.792 total time=   3.3s\n",
      "[CV 5/5; 1/12] START learning_rate=0.05, max_depth=6, n_estimators=200..........\n",
      "[CV 5/5; 1/12] END learning_rate=0.05, max_depth=6, n_estimators=200;, score=0.787 total time=   2.8s\n",
      "[CV 1/5; 2/12] START learning_rate=0.05, max_depth=6, n_estimators=300..........\n",
      "[CV 1/5; 2/12] END learning_rate=0.05, max_depth=6, n_estimators=300;, score=0.802 total time=   4.4s\n",
      "[CV 2/5; 2/12] START learning_rate=0.05, max_depth=6, n_estimators=300..........\n",
      "[CV 2/5; 2/12] END learning_rate=0.05, max_depth=6, n_estimators=300;, score=0.808 total time=   6.3s\n",
      "[CV 3/5; 2/12] START learning_rate=0.05, max_depth=6, n_estimators=300..........\n",
      "[CV 3/5; 2/12] END learning_rate=0.05, max_depth=6, n_estimators=300;, score=0.796 total time=   5.1s\n",
      "[CV 4/5; 2/12] START learning_rate=0.05, max_depth=6, n_estimators=300..........\n",
      "[CV 4/5; 2/12] END learning_rate=0.05, max_depth=6, n_estimators=300;, score=0.787 total time=   5.6s\n",
      "[CV 5/5; 2/12] START learning_rate=0.05, max_depth=6, n_estimators=300..........\n",
      "[CV 5/5; 2/12] END learning_rate=0.05, max_depth=6, n_estimators=300;, score=0.791 total time=   5.3s\n",
      "[CV 1/5; 3/12] START learning_rate=0.05, max_depth=8, n_estimators=200..........\n",
      "[CV 1/5; 3/12] END learning_rate=0.05, max_depth=8, n_estimators=200;, score=0.809 total time=   8.2s\n",
      "[CV 2/5; 3/12] START learning_rate=0.05, max_depth=8, n_estimators=200..........\n",
      "[CV 2/5; 3/12] END learning_rate=0.05, max_depth=8, n_estimators=200;, score=0.810 total time=   6.6s\n",
      "[CV 3/5; 3/12] START learning_rate=0.05, max_depth=8, n_estimators=200..........\n",
      "[CV 3/5; 3/12] END learning_rate=0.05, max_depth=8, n_estimators=200;, score=0.793 total time=   6.4s\n",
      "[CV 4/5; 3/12] START learning_rate=0.05, max_depth=8, n_estimators=200..........\n",
      "[CV 4/5; 3/12] END learning_rate=0.05, max_depth=8, n_estimators=200;, score=0.789 total time=   6.4s\n",
      "[CV 5/5; 3/12] START learning_rate=0.05, max_depth=8, n_estimators=200..........\n",
      "[CV 5/5; 3/12] END learning_rate=0.05, max_depth=8, n_estimators=200;, score=0.788 total time=   8.6s\n",
      "[CV 1/5; 4/12] START learning_rate=0.05, max_depth=8, n_estimators=300..........\n",
      "[CV 1/5; 4/12] END learning_rate=0.05, max_depth=8, n_estimators=300;, score=0.809 total time=   9.8s\n",
      "[CV 2/5; 4/12] START learning_rate=0.05, max_depth=8, n_estimators=300..........\n",
      "[CV 2/5; 4/12] END learning_rate=0.05, max_depth=8, n_estimators=300;, score=0.807 total time=  11.5s\n",
      "[CV 3/5; 4/12] START learning_rate=0.05, max_depth=8, n_estimators=300..........\n",
      "[CV 3/5; 4/12] END learning_rate=0.05, max_depth=8, n_estimators=300;, score=0.798 total time=  10.5s\n",
      "[CV 4/5; 4/12] START learning_rate=0.05, max_depth=8, n_estimators=300..........\n",
      "[CV 4/5; 4/12] END learning_rate=0.05, max_depth=8, n_estimators=300;, score=0.790 total time=  10.9s\n",
      "[CV 5/5; 4/12] START learning_rate=0.05, max_depth=8, n_estimators=300..........\n",
      "[CV 5/5; 4/12] END learning_rate=0.05, max_depth=8, n_estimators=300;, score=0.786 total time=  10.7s\n",
      "[CV 1/5; 5/12] START learning_rate=0.05, max_depth=10, n_estimators=200.........\n",
      "[CV 1/5; 5/12] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.804 total time=  12.6s\n",
      "[CV 2/5; 5/12] START learning_rate=0.05, max_depth=10, n_estimators=200.........\n",
      "[CV 2/5; 5/12] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.806 total time=  12.3s\n",
      "[CV 3/5; 5/12] START learning_rate=0.05, max_depth=10, n_estimators=200.........\n",
      "[CV 3/5; 5/12] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.789 total time=  12.6s\n",
      "[CV 4/5; 5/12] START learning_rate=0.05, max_depth=10, n_estimators=200.........\n",
      "[CV 4/5; 5/12] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.781 total time=  12.6s\n",
      "[CV 5/5; 5/12] START learning_rate=0.05, max_depth=10, n_estimators=200.........\n",
      "[CV 5/5; 5/12] END learning_rate=0.05, max_depth=10, n_estimators=200;, score=0.783 total time=  12.4s\n",
      "[CV 1/5; 6/12] START learning_rate=0.05, max_depth=10, n_estimators=300.........\n",
      "[CV 1/5; 6/12] END learning_rate=0.05, max_depth=10, n_estimators=300;, score=0.807 total time=  15.9s\n",
      "[CV 2/5; 6/12] START learning_rate=0.05, max_depth=10, n_estimators=300.........\n",
      "[CV 2/5; 6/12] END learning_rate=0.05, max_depth=10, n_estimators=300;, score=0.807 total time=  16.2s\n",
      "[CV 3/5; 6/12] START learning_rate=0.05, max_depth=10, n_estimators=300.........\n",
      "[CV 3/5; 6/12] END learning_rate=0.05, max_depth=10, n_estimators=300;, score=0.791 total time=  15.2s\n",
      "[CV 4/5; 6/12] START learning_rate=0.05, max_depth=10, n_estimators=300.........\n",
      "[CV 4/5; 6/12] END learning_rate=0.05, max_depth=10, n_estimators=300;, score=0.784 total time=  15.5s\n",
      "[CV 5/5; 6/12] START learning_rate=0.05, max_depth=10, n_estimators=300.........\n",
      "[CV 5/5; 6/12] END learning_rate=0.05, max_depth=10, n_estimators=300;, score=0.790 total time=  15.5s\n",
      "[CV 1/5; 7/12] START learning_rate=0.1, max_depth=6, n_estimators=200...........\n",
      "[CV 1/5; 7/12] END learning_rate=0.1, max_depth=6, n_estimators=200;, score=0.809 total time=   4.3s\n",
      "[CV 2/5; 7/12] START learning_rate=0.1, max_depth=6, n_estimators=200...........\n",
      "[CV 2/5; 7/12] END learning_rate=0.1, max_depth=6, n_estimators=200;, score=0.810 total time=   3.4s\n",
      "[CV 3/5; 7/12] START learning_rate=0.1, max_depth=6, n_estimators=200...........\n",
      "[CV 3/5; 7/12] END learning_rate=0.1, max_depth=6, n_estimators=200;, score=0.791 total time=   3.8s\n",
      "[CV 4/5; 7/12] START learning_rate=0.1, max_depth=6, n_estimators=200...........\n",
      "[CV 4/5; 7/12] END learning_rate=0.1, max_depth=6, n_estimators=200;, score=0.778 total time=   3.6s\n",
      "[CV 5/5; 7/12] START learning_rate=0.1, max_depth=6, n_estimators=200...........\n",
      "[CV 5/5; 7/12] END learning_rate=0.1, max_depth=6, n_estimators=200;, score=0.783 total time=   3.7s\n",
      "[CV 1/5; 8/12] START learning_rate=0.1, max_depth=6, n_estimators=300...........\n",
      "[CV 1/5; 8/12] END learning_rate=0.1, max_depth=6, n_estimators=300;, score=0.810 total time=   5.2s\n",
      "[CV 2/5; 8/12] START learning_rate=0.1, max_depth=6, n_estimators=300...........\n",
      "[CV 2/5; 8/12] END learning_rate=0.1, max_depth=6, n_estimators=300;, score=0.814 total time=   5.5s\n",
      "[CV 3/5; 8/12] START learning_rate=0.1, max_depth=6, n_estimators=300...........\n",
      "[CV 3/5; 8/12] END learning_rate=0.1, max_depth=6, n_estimators=300;, score=0.788 total time=   5.0s\n",
      "[CV 4/5; 8/12] START learning_rate=0.1, max_depth=6, n_estimators=300...........\n",
      "[CV 4/5; 8/12] END learning_rate=0.1, max_depth=6, n_estimators=300;, score=0.789 total time=   5.2s\n",
      "[CV 5/5; 8/12] START learning_rate=0.1, max_depth=6, n_estimators=300...........\n",
      "[CV 5/5; 8/12] END learning_rate=0.1, max_depth=6, n_estimators=300;, score=0.780 total time=   5.4s\n",
      "[CV 1/5; 9/12] START learning_rate=0.1, max_depth=8, n_estimators=200...........\n",
      "[CV 1/5; 9/12] END learning_rate=0.1, max_depth=8, n_estimators=200;, score=0.806 total time=   7.9s\n",
      "[CV 2/5; 9/12] START learning_rate=0.1, max_depth=8, n_estimators=200...........\n",
      "[CV 2/5; 9/12] END learning_rate=0.1, max_depth=8, n_estimators=200;, score=0.812 total time=   6.9s\n",
      "[CV 3/5; 9/12] START learning_rate=0.1, max_depth=8, n_estimators=200...........\n",
      "[CV 3/5; 9/12] END learning_rate=0.1, max_depth=8, n_estimators=200;, score=0.787 total time=   6.8s\n",
      "[CV 4/5; 9/12] START learning_rate=0.1, max_depth=8, n_estimators=200...........\n",
      "[CV 4/5; 9/12] END learning_rate=0.1, max_depth=8, n_estimators=200;, score=0.784 total time=   7.1s\n",
      "[CV 5/5; 9/12] START learning_rate=0.1, max_depth=8, n_estimators=200...........\n",
      "[CV 5/5; 9/12] END learning_rate=0.1, max_depth=8, n_estimators=200;, score=0.784 total time=   6.6s\n",
      "[CV 1/5; 10/12] START learning_rate=0.1, max_depth=8, n_estimators=300..........\n",
      "[CV 1/5; 10/12] END learning_rate=0.1, max_depth=8, n_estimators=300;, score=0.802 total time=   8.9s\n",
      "[CV 2/5; 10/12] START learning_rate=0.1, max_depth=8, n_estimators=300..........\n",
      "[CV 2/5; 10/12] END learning_rate=0.1, max_depth=8, n_estimators=300;, score=0.810 total time=   8.7s\n",
      "[CV 3/5; 10/12] START learning_rate=0.1, max_depth=8, n_estimators=300..........\n",
      "[CV 3/5; 10/12] END learning_rate=0.1, max_depth=8, n_estimators=300;, score=0.791 total time=   9.0s\n",
      "[CV 4/5; 10/12] START learning_rate=0.1, max_depth=8, n_estimators=300..........\n",
      "[CV 4/5; 10/12] END learning_rate=0.1, max_depth=8, n_estimators=300;, score=0.783 total time=   9.1s\n",
      "[CV 5/5; 10/12] START learning_rate=0.1, max_depth=8, n_estimators=300..........\n",
      "[CV 5/5; 10/12] END learning_rate=0.1, max_depth=8, n_estimators=300;, score=0.786 total time=   9.2s\n",
      "[CV 1/5; 11/12] START learning_rate=0.1, max_depth=10, n_estimators=200.........\n",
      "[CV 1/5; 11/12] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.808 total time=   9.3s\n",
      "[CV 2/5; 11/12] START learning_rate=0.1, max_depth=10, n_estimators=200.........\n",
      "[CV 2/5; 11/12] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.804 total time=   9.4s\n",
      "[CV 3/5; 11/12] START learning_rate=0.1, max_depth=10, n_estimators=200.........\n",
      "[CV 3/5; 11/12] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.787 total time=   9.3s\n",
      "[CV 4/5; 11/12] START learning_rate=0.1, max_depth=10, n_estimators=200.........\n",
      "[CV 4/5; 11/12] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.781 total time=   9.6s\n",
      "[CV 5/5; 11/12] START learning_rate=0.1, max_depth=10, n_estimators=200.........\n",
      "[CV 5/5; 11/12] END learning_rate=0.1, max_depth=10, n_estimators=200;, score=0.790 total time=  10.3s\n",
      "[CV 1/5; 12/12] START learning_rate=0.1, max_depth=10, n_estimators=300.........\n",
      "[CV 1/5; 12/12] END learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.809 total time=  11.4s\n",
      "[CV 2/5; 12/12] START learning_rate=0.1, max_depth=10, n_estimators=300.........\n",
      "[CV 2/5; 12/12] END learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.807 total time=  11.7s\n",
      "[CV 3/5; 12/12] START learning_rate=0.1, max_depth=10, n_estimators=300.........\n",
      "[CV 3/5; 12/12] END learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.789 total time=  12.3s\n",
      "[CV 4/5; 12/12] START learning_rate=0.1, max_depth=10, n_estimators=300.........\n",
      "[CV 4/5; 12/12] END learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.787 total time=  12.7s\n",
      "[CV 5/5; 12/12] START learning_rate=0.1, max_depth=10, n_estimators=300.........\n",
      "[CV 5/5; 12/12] END learning_rate=0.1, max_depth=10, n_estimators=300;, score=0.792 total time=  11.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_typ...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_typ...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [6, 8, 10],\n",
       "                         &#x27;n_estimators&#x27;: [200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_typ...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.05, 0.1], 'max_depth': [6, 8, 10],\n",
       "                         'n_estimators': [200, 300]},\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": [200, 300],\n",
    "    \"max_depth\": [6, 8, 10],\n",
    "    \"learning_rate\": [0.05, 0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(XGBClassifier(), params, cv=kf, scoring=\"neg_root_mean_squared_error\", verbose=10)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "454858a8-2a74-44e8-8f7a-d4b0b70f5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7983689429621839\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\", grid.best_score_)\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303e8b5-d247-427a-b2bf-2b45b01ce7c1",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1126120e-f6fd-46a8-9e12-fe0cd2998efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filling nulls\n",
    "df_test = df_test.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f1e0d159-2f1f-432a-be80-845e1cdbb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_test[\"tweet_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "352ce788-5dfe-4b03-bba5-b7d36ed57d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_dataframe(model, data):\n",
    "    '''Make a prediction on a dataframe'''\n",
    "    pred_text = data[\"safe_text\"].apply(lambda x: full_text_process(x)).values\n",
    "    pred_text = vectorizer.transform(pred_text)\n",
    "    return grid.predict(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "17e4d6ee-d121-4830-a7e9-896c57f6fa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence at index:11 has no word in the vector dictionary\n",
      "Sentence at index:65 has no word in the vector dictionary\n",
      "Sentence at index:74 has no word in the vector dictionary\n",
      "Sentence at index:80 has no word in the vector dictionary\n",
      "Sentence at index:93 has no word in the vector dictionary\n",
      "Sentence at index:116 has no word in the vector dictionary\n",
      "Sentence at index:204 has no word in the vector dictionary\n",
      "Sentence at index:217 has no word in the vector dictionary\n",
      "Sentence at index:225 has no word in the vector dictionary\n",
      "Sentence at index:235 has no word in the vector dictionary\n",
      "Sentence at index:241 has no word in the vector dictionary\n",
      "Sentence at index:311 has no word in the vector dictionary\n",
      "Sentence at index:377 has no word in the vector dictionary\n",
      "Sentence at index:397 has no word in the vector dictionary\n",
      "Sentence at index:550 has no word in the vector dictionary\n",
      "Sentence at index:663 has no word in the vector dictionary\n",
      "Sentence at index:693 has no word in the vector dictionary\n",
      "Sentence at index:724 has no word in the vector dictionary\n",
      "Sentence at index:741 has no word in the vector dictionary\n",
      "Sentence at index:758 has no word in the vector dictionary\n",
      "Sentence at index:891 has no word in the vector dictionary\n",
      "Sentence at index:920 has no word in the vector dictionary\n",
      "Sentence at index:931 has no word in the vector dictionary\n",
      "Sentence at index:951 has no word in the vector dictionary\n",
      "Sentence at index:973 has no word in the vector dictionary\n",
      "Sentence at index:990 has no word in the vector dictionary\n",
      "Sentence at index:999 has no word in the vector dictionary\n",
      "Sentence at index:1058 has no word in the vector dictionary\n",
      "Sentence at index:1077 has no word in the vector dictionary\n",
      "Sentence at index:1145 has no word in the vector dictionary\n",
      "Sentence at index:1151 has no word in the vector dictionary\n",
      "Sentence at index:1154 has no word in the vector dictionary\n",
      "Sentence at index:1181 has no word in the vector dictionary\n",
      "Sentence at index:1297 has no word in the vector dictionary\n",
      "Sentence at index:1379 has no word in the vector dictionary\n",
      "Sentence at index:1391 has no word in the vector dictionary\n",
      "Sentence at index:1462 has no word in the vector dictionary\n",
      "Sentence at index:1465 has no word in the vector dictionary\n",
      "Sentence at index:1468 has no word in the vector dictionary\n",
      "Sentence at index:1478 has no word in the vector dictionary\n",
      "Sentence at index:1592 has no word in the vector dictionary\n",
      "Sentence at index:1633 has no word in the vector dictionary\n",
      "Sentence at index:1648 has no word in the vector dictionary\n",
      "Sentence at index:1697 has no word in the vector dictionary\n",
      "Sentence at index:1751 has no word in the vector dictionary\n",
      "Sentence at index:1767 has no word in the vector dictionary\n",
      "Sentence at index:1801 has no word in the vector dictionary\n",
      "Sentence at index:1875 has no word in the vector dictionary\n",
      "Sentence at index:1906 has no word in the vector dictionary\n",
      "Sentence at index:1917 has no word in the vector dictionary\n",
      "Sentence at index:1921 has no word in the vector dictionary\n",
      "Sentence at index:1943 has no word in the vector dictionary\n",
      "Sentence at index:1966 has no word in the vector dictionary\n",
      "Sentence at index:1983 has no word in the vector dictionary\n",
      "Sentence at index:2021 has no word in the vector dictionary\n",
      "Sentence at index:2024 has no word in the vector dictionary\n",
      "Sentence at index:2027 has no word in the vector dictionary\n",
      "Sentence at index:2064 has no word in the vector dictionary\n",
      "Sentence at index:2077 has no word in the vector dictionary\n",
      "Sentence at index:2116 has no word in the vector dictionary\n",
      "Sentence at index:2205 has no word in the vector dictionary\n",
      "Sentence at index:2209 has no word in the vector dictionary\n",
      "Sentence at index:2238 has no word in the vector dictionary\n",
      "Sentence at index:2303 has no word in the vector dictionary\n",
      "Sentence at index:2319 has no word in the vector dictionary\n",
      "Sentence at index:2322 has no word in the vector dictionary\n",
      "Sentence at index:2341 has no word in the vector dictionary\n",
      "Sentence at index:2347 has no word in the vector dictionary\n",
      "Sentence at index:2356 has no word in the vector dictionary\n",
      "Sentence at index:2465 has no word in the vector dictionary\n",
      "Sentence at index:2500 has no word in the vector dictionary\n",
      "Sentence at index:2517 has no word in the vector dictionary\n",
      "Sentence at index:2541 has no word in the vector dictionary\n",
      "Sentence at index:2560 has no word in the vector dictionary\n",
      "Sentence at index:2570 has no word in the vector dictionary\n",
      "Sentence at index:2593 has no word in the vector dictionary\n",
      "Sentence at index:2608 has no word in the vector dictionary\n",
      "Sentence at index:2690 has no word in the vector dictionary\n",
      "Sentence at index:2702 has no word in the vector dictionary\n",
      "Sentence at index:2770 has no word in the vector dictionary\n",
      "Sentence at index:2771 has no word in the vector dictionary\n",
      "Sentence at index:2805 has no word in the vector dictionary\n",
      "Sentence at index:2857 has no word in the vector dictionary\n",
      "Sentence at index:2896 has no word in the vector dictionary\n",
      "Sentence at index:2928 has no word in the vector dictionary\n",
      "Sentence at index:2936 has no word in the vector dictionary\n",
      "Sentence at index:2951 has no word in the vector dictionary\n",
      "Sentence at index:2968 has no word in the vector dictionary\n",
      "Sentence at index:3051 has no word in the vector dictionary\n",
      "Sentence at index:3135 has no word in the vector dictionary\n",
      "Sentence at index:3153 has no word in the vector dictionary\n",
      "Sentence at index:3187 has no word in the vector dictionary\n",
      "Sentence at index:3221 has no word in the vector dictionary\n",
      "Sentence at index:3243 has no word in the vector dictionary\n",
      "Sentence at index:3250 has no word in the vector dictionary\n",
      "Sentence at index:3251 has no word in the vector dictionary\n",
      "Sentence at index:3346 has no word in the vector dictionary\n",
      "Sentence at index:3437 has no word in the vector dictionary\n",
      "Sentence at index:3453 has no word in the vector dictionary\n",
      "Sentence at index:3461 has no word in the vector dictionary\n",
      "Sentence at index:3566 has no word in the vector dictionary\n",
      "Sentence at index:3588 has no word in the vector dictionary\n",
      "Sentence at index:3671 has no word in the vector dictionary\n",
      "Sentence at index:3744 has no word in the vector dictionary\n",
      "Sentence at index:3802 has no word in the vector dictionary\n",
      "Sentence at index:3859 has no word in the vector dictionary\n",
      "Sentence at index:3914 has no word in the vector dictionary\n",
      "Sentence at index:3985 has no word in the vector dictionary\n",
      "Sentence at index:3998 has no word in the vector dictionary\n",
      "Sentence at index:4090 has no word in the vector dictionary\n",
      "Sentence at index:4107 has no word in the vector dictionary\n",
      "Sentence at index:4138 has no word in the vector dictionary\n",
      "Sentence at index:4149 has no word in the vector dictionary\n",
      "Sentence at index:4204 has no word in the vector dictionary\n",
      "Sentence at index:4205 has no word in the vector dictionary\n",
      "Sentence at index:4244 has no word in the vector dictionary\n",
      "Sentence at index:4306 has no word in the vector dictionary\n",
      "Sentence at index:4348 has no word in the vector dictionary\n",
      "Sentence at index:4356 has no word in the vector dictionary\n",
      "Sentence at index:4414 has no word in the vector dictionary\n",
      "Sentence at index:4565 has no word in the vector dictionary\n",
      "Sentence at index:4647 has no word in the vector dictionary\n",
      "Sentence at index:4655 has no word in the vector dictionary\n",
      "Sentence at index:4667 has no word in the vector dictionary\n",
      "Sentence at index:4832 has no word in the vector dictionary\n",
      "Sentence at index:4842 has no word in the vector dictionary\n",
      "Sentence at index:4883 has no word in the vector dictionary\n",
      "Sentence at index:4887 has no word in the vector dictionary\n",
      "Sentence at index:4910 has no word in the vector dictionary\n",
      "Sentence at index:4914 has no word in the vector dictionary\n",
      "Sentence at index:5001 has no word in the vector dictionary\n",
      "Sentence at index:5043 has no word in the vector dictionary\n",
      "Sentence at index:5136 has no word in the vector dictionary\n"
     ]
    }
   ],
   "source": [
    "# pred_text = df_test[\"text\"].apply(lambda x: full_text_process(x)).values\n",
    "# pred_text = vectorizer.transform(pred_text)\n",
    "preds = predict_on_dataframe(grid, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053a8c5-bebd-4db4-a35f-85421590561e",
   "metadata": {},
   "source": [
    "### Submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "07d4766f-0580-4707-bedf-d18ae28d1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"tweet_id\": ids, \"target\":np.clip(preds, -1, 1)})\n",
    "\n",
    "if not os.path.exists(\"x__submissions\"):\n",
    "    os.mkdir(\"x__submissions\")\n",
    "\n",
    "save_name = \"glove_rfr.csv\"\n",
    "submission.to_csv(f\"x__submissions/{save_name}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8418d8ff-29ca-4b7d-b6c8-02f4677af265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## creating submission dataframe\n",
    "# ids = df_test[\"id\"].values\n",
    "\n",
    "# sub_df = pd.DataFrame({\"id\": ids, \"target\": preds.astype(int)})\n",
    "\n",
    "# ## saving as csv\n",
    "# if not os.path.exists(\"x__submissions\"):\n",
    "#     os.mkdir(\"x__submissions\")\n",
    "\n",
    "# sub_df.to_csv(\"x__submissions/sub_glove_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71617e0c-49ff-4489-be49-5120c2241636",
   "metadata": {},
   "source": [
    "### Saving Necessary Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "222493fa-4ca2-48a6-a8fa-7077f42391fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "306336a5-e2d8-403d-aeda-82cdcbbbf9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating transformer\n",
    "class TweetTransformer():\n",
    "    def __init__(self, word2idx, vectors):\n",
    "        self.word2idx = word2idx\n",
    "        self.vectors = vectors\n",
    "\n",
    "    ## function to preprocessing of text\n",
    "    def process_text(self, text):\n",
    "        ## patterns to remove\n",
    "        rem_pat_1 = \"([@]|https?:)\\S*\"\n",
    "        rem_pat_2 = \"&\\S+;\"\n",
    "        rem_pat_3 = \"\\[\\d+:\\d+.+\\]\" ## removing timestamp. eg. [01:04 UTC]\n",
    "        rem_pat_4 = \"[\\-_.+#]\" ## to remove symbols (make sure to bring last to avoid affecting first two patterns)\n",
    "        combined_rem_pat = f\"({rem_pat_1})|({rem_pat_2})|({rem_pat_3})|({rem_pat_4})\"\n",
    "    \n",
    "        text = re.sub(combined_rem_pat, \"\", text) ## removing text that match patterns\n",
    "        text = text.strip() ## removing trailing white spaces\n",
    "        text = text.lower() ## lowercasing\n",
    "    \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def full_text_process(self, text):\n",
    "        text = self.process_text(text)\n",
    "        return text\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        if isinstance(X, str):\n",
    "            X = [self.full_text_process(X)]\n",
    "            \n",
    "        N = len(X)\n",
    "        X = [self.full_text_process(x) for x in X]\n",
    "            \n",
    "        transformed_x = np.zeros((N, self.vectors.shape[1]), dtype=np.float32)\n",
    "        for i in range(N):\n",
    "            mat = []\n",
    "            line = X[i].lower().split()\n",
    "            for word in line:\n",
    "                if word in self.word2idx:\n",
    "                    mat.append(self.vectors[self.word2idx[word]])\n",
    "\n",
    "            if len(mat) > 0: transformed_x[i] = np.mean(mat, axis=0)\n",
    "            else: print(f\"Sentence at index:{i} has no word in the vector dictionary\")\n",
    "\n",
    "        return np.array(transformed_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d13a1d22-d21b-4028-899a-3f36a87e1107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(max_depth=16, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(max_depth=16, n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(max_depth=16, n_estimators=500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = ExtraTreesClassifier(**{'max_depth': 16, 'n_estimators': 500})\n",
    "estimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "43a287e8-70a8-4e79-98d5-4fb75a27819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating transformer\n",
    "transformer = TweetTransformer(vectorizer.word2idx, vectorizer.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10b30ac3-72eb-448a-aba1-58c94751f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"x__serialized\"\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "## saving model\n",
    "with open(os.path.join(save_folder, \"disaster_tweets_classifier.pickle\"), \"wb\") as file:\n",
    "    pickle.dump(estimator, file)\n",
    "\n",
    "# ## saving transformer\n",
    "# with open(os.path.join(save_folder, \"disaster_tweets_transformer.pickle\"), \"wb\") as file:\n",
    "#     pickle.dump(transformer, file)\n",
    "\n",
    "## saving word2idx and vectors\n",
    "with open(os.path.join(save_folder, \"disaster_tweets_word_vectors.pickle\"), \"wb\") as file:\n",
    "    pickle.dump({\"word2idx\": vectorizer.word2idx, \"vectors\": vectorizer.vectors}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "63a3b9b7-72ec-4957-8efa-a6d1bbe5bdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence at index:24 has no word in the vector dictionary\n",
      "Sentence at index:783 has no word in the vector dictionary\n",
      "Sentence at index:2586 has no word in the vector dictionary\n",
      "Sentence at index:3667 has no word in the vector dictionary\n",
      "Sentence at index:3681 has no word in the vector dictionary\n",
      "Sentence at index:3683 has no word in the vector dictionary\n",
      "Sentence at index:4092 has no word in the vector dictionary\n",
      "Sentence at index:4504 has no word in the vector dictionary\n",
      "Sentence at index:5115 has no word in the vector dictionary\n",
      "Sentence at index:5353 has no word in the vector dictionary\n",
      "Sentence at index:5983 has no word in the vector dictionary\n",
      "Sentence at index:5987 has no word in the vector dictionary\n",
      "Sentence at index:5988 has no word in the vector dictionary\n",
      "Sentence at index:5998 has no word in the vector dictionary\n",
      "Sentence at index:6313 has no word in the vector dictionary\n",
      "Sentence at index:6522 has no word in the vector dictionary\n",
      "Sentence at index:6705 has no word in the vector dictionary\n",
      "Sentence at index:6907 has no word in the vector dictionary\n",
      "Sentence at index:7210 has no word in the vector dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict(transformer.transform(train_text))[:30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
