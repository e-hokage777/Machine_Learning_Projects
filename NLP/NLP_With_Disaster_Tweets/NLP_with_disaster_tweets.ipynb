{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "8d0b6ba9-f744-4430-a0b0-b5f83e13eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "e6ca8ea9-74e5-4d7c-a087-9f2aac299be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = stopwords.words(\"english\")\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "3087da1e-e6fc-4e93-b0ad-d061ec1d13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the data\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "415c453f-2e85-488f-a070-0865f0369fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "d3613a7d-d526-4c81-be0b-ab82dd7e7311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking for missing\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "32e14424-354f-47a2-a7dd-826088b2b86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "sinking                  41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: count, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking the keyword column\n",
    "df_train[\"keyword\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "52bebafc-1905-4f92-8ac1-4744692559de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>10826</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>TN</td>\n",
       "      <td>On the bright side I wrecked http://t.co/uEa0t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>10829</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>#NewcastleuponTyne #UK</td>\n",
       "      <td>@widda16 ... He's gone. You can relax. I thoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>10831</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>Three days off from work and they've pretty mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>London</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5080 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                       location  \\\n",
       "31       48   ablaze                     Birmingham   \n",
       "32       49   ablaze  Est. September 2012 - Bristol   \n",
       "33       50   ablaze                         AFRICA   \n",
       "34       52   ablaze               Philadelphia, PA   \n",
       "35       53   ablaze                     London, UK   \n",
       "...     ...      ...                            ...   \n",
       "7575  10826  wrecked                             TN   \n",
       "7577  10829  wrecked         #NewcastleuponTyne #UK   \n",
       "7579  10831  wrecked              Vancouver, Canada   \n",
       "7580  10832  wrecked                        London    \n",
       "7581  10833  wrecked                        Lincoln   \n",
       "\n",
       "                                                   text  target  \n",
       "31    @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32    We always try to bring the heavy. #metal #RT h...       0  \n",
       "33    #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                   Crying out for more! Set me ablaze       0  \n",
       "35    On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  \n",
       "...                                                 ...     ...  \n",
       "7575  On the bright side I wrecked http://t.co/uEa0t...       0  \n",
       "7577  @widda16 ... He's gone. You can relax. I thoug...       0  \n",
       "7579  Three days off from work and they've pretty mu...       0  \n",
       "7580  #FX #forex #trading Cramer: Iger's 3 words tha...       0  \n",
       "7581  @engineshed Great atmosphere at the British Li...       0  \n",
       "\n",
       "[5080 rows x 5 columns]"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"location\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "a28b781e-a5f4-4394-a929-e162d6cbf73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "id": "096a961f-65e2-474c-bd94-6c4cc25d92f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Today is the day Hiroshima got Atomic bomb 70 years ago.  - The 'sanitised narrative' of Hiroshima's atomic bombing http://t.co/GKpANz7vg0\",\n",
       "       \"@Drake is body bagging meek meanwhile he's on tour with Nicki all hush hush...he's put 2 diss tracks out and meek 0 but dude started it lol\",\n",
       "       \"Pakistan says army helicopter has crashed in country's restive northwest killing at least 8 http://t.co/QV1RMZI3J1\",\n",
       "       'I got evacuated from the cinema 30 mins through Inside Out\\r\\nKill me please',\n",
       "       \"don't get on I77 south... huge wreck and airlift and maybe some deaths interstate is completely blocked\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 997,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking the nature of the tweets\n",
    "\n",
    "df_train[\"text\"].sample(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "789a3db4-9661-45e4-a9b1-b178b7eeddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for cleaning function\n",
    "## - remove urls\n",
    "## - remove # tags\n",
    "## - remove html special characters eg &amp;\n",
    "## - remove @text\n",
    "## - remove [01:04 UTC]\n",
    "## - strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "2d60ad2e-12cd-4956-9e59-bc08f066ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "## function to preprocessing of text\n",
    "def process_text(text):\n",
    "    ## patterns to remove\n",
    "    rem_pat_1 = \"([#@]|https?:)\\S*\"\n",
    "    rem_pat_2 = \"&\\S+;\"\n",
    "    rem_pat_3 = \"\\[\\d+:\\d+.+\\]\" ## removing timestamp. eg. [01:04 UTC]\n",
    "    rem_pat_4 = \"[\\-_.+]\" ## to remove symbols (make sure to bring last to avoid affecting first two patterns)\n",
    "    combined_rem_pat = f\"({rem_pat_1})|({rem_pat_2})|({rem_pat_3})|({rem_pat_4})\"\n",
    "\n",
    "    text = re.sub(combined_rem_pat, \"\", text) ## removing text that match patterns\n",
    "    text = text.strip() ## removing trailing white spaces\n",
    "    text = text.lower() ## lowercasing\n",
    "\n",
    "    return text\n",
    "\n",
    "## function for tokenizing of string\n",
    "def tokenize(text):\n",
    "    return re.split(\"\\s+\", text)\n",
    "\n",
    "## function to remove stop words\n",
    "def remove_stopwords(token_list):\n",
    "    l = []\n",
    "    for word in token_list:\n",
    "        if word not in stopwords:\n",
    "            l.append(word)\n",
    "    return l\n",
    "\n",
    "def full_text_process(text):\n",
    "    text = process_text(text)\n",
    "    text = tokenize(text)\n",
    "    # text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "1c2f0e9d-009b-4bff-8c5f-9506b8a01653",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the training and testing processed data\n",
    "## train\n",
    "train_text = df_train[\"text\"].apply(lambda x: full_text_process(x)).values\n",
    "train_target = df_train[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "id": "da996b2a-3faf-4f00-97c7-c9e7a71eaaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['deeds', 'reason', 'may', 'allah', 'forgive', 'us']),\n",
       "       list(['forest', 'fire', 'near', 'la', 'ronge', 'sask', 'canada']),\n",
       "       list(['residents', 'asked', \"'shelter\", \"place'\", 'notified', 'officers', 'evacuation', 'shelter', 'place', 'orders', 'expected']),\n",
       "       ..., list(['m194', '?5km', 'volcano', 'hawaii']),\n",
       "       list(['police', 'investigating', 'ebike', 'collided', 'car', 'little', 'portugal', 'ebike', 'rider', 'suffered', 'serious', 'nonlife', 'threatening', 'injuries']),\n",
       "       list(['latest:', 'homes', 'razed', 'northern', 'california', 'wildfire', 'abc', 'news'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "8f22c46d-9038-4bb1-ace6-41586d1f9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating word dictionary\n",
    "word2idx = {\"<pad>\": 0}\n",
    "count = 1\n",
    "\n",
    "for l in train_text:\n",
    "    for i in range(len(l)):\n",
    "        if l[i] not in word2idx:\n",
    "            word2idx[l[i]] = count\n",
    "            count+=1\n",
    "\n",
    "        l[i] = word2idx[l[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "ae8a3d53-a463-4f18-8595-8710ec47f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to convert token list to integer list\n",
    "def token_to_int(text_data, word2idx):\n",
    "    for i in range(len(text_data)):\n",
    "        idx_list = []\n",
    "        for word in text_data[i]:\n",
    "            if word in word2idx:\n",
    "                idx_list.append(word2idx[word])\n",
    "        text_data[i] = idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "28ba2d0c-4703-4275-a3f6-bcfbaab95be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating train and validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_text, train_target, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "44611494-663b-43c9-836c-ba7f4682e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating data loaders\n",
    "def data_loader(inputs, targets, batch_size=64):\n",
    "    inputs, targets = shuffle(inputs, targets)\n",
    "    n = len(inputs)\n",
    "    num_batches = math.ceil(n/batch_size)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min(start_idx+batch_size, n)\n",
    "\n",
    "        ## getting the batch data\n",
    "        inputs_batch = inputs[start_idx:end_idx]\n",
    "        targets_batch = targets[start_idx:end_idx]\n",
    "\n",
    "        ## padding the inputs\n",
    "        max_len = max([len(l) for l in inputs_batch])\n",
    "\n",
    "        for j in range(len(inputs_batch)):\n",
    "            pad_len = max_len - len(inputs_batch[j])\n",
    "            inputs_batch[j] = [0]*pad_len + inputs_batch[j]\n",
    "\n",
    "        yield np.array([*inputs_batch]),  targets_batch.reshape(-1,1).astype(np.float32)\n",
    "        \n",
    "## creating data loader for submissing data\n",
    "def data_loader_no_target(inputs, batch_size=64):\n",
    "    n = len(inputs)\n",
    "    num_batches = math.ceil(n/batch_size)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min(start_idx+batch_size, n)\n",
    "\n",
    "        ## getting the batch data\n",
    "        inputs_batch = inputs[start_idx:end_idx]\n",
    "\n",
    "        ## padding the inputs\n",
    "        max_len = max([len(l) for l in inputs_batch])\n",
    "\n",
    "        for j in range(len(inputs_batch)):\n",
    "            pad_len = max_len - len(inputs_batch[j])\n",
    "            inputs_batch[j] = [0]*pad_len + inputs_batch[j]\n",
    "\n",
    "        yield np.array([*inputs_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "61ee62d7-c676-4371-bf52-617e8c3e1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = lambda: data_loader(X_train, y_train, batch_size=batch_size)\n",
    "test_loader = lambda: data_loader(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "0fd33b7d-9939-41fd-bf05-f797b7adabed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(Model, self).__init__()\n",
    "        self.V = vocab_size\n",
    "        self.D = embed_size\n",
    "        self.M = hidden_size\n",
    "        self.L = num_layers\n",
    "    \n",
    "        self.embed = nn.Embedding(self.V, self.D)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.D,\n",
    "            hidden_size=self.M,\n",
    "            num_layers=self.L,\n",
    "            batch_first=True\n",
    "        )\n",
    "    \n",
    "        self.fc = nn.Linear(self.M, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        c0 = torch.zeros(self.L, X.size(0), self.M)\n",
    "        h0 = torch.zeros(self.L, X.size(0), self.M)\n",
    "\n",
    "        out = self.embed(X)\n",
    "\n",
    "        out, _ = self.rnn(out, (c0,h0))\n",
    "        \n",
    "        out, _ = torch.max(out, 1) ## global max pooling\n",
    "        # out = out[:,-1,:] ## selecting last layer\n",
    "\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "id": "a93132ae-fc8a-44f1-9a3a-01b887894430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(len(word2idx), 10, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "id": "b0758b65-16ef-4b64-b597-0909ae1c4b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "a2027860-9475-4077-80e3-f6e59eac5bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embed): Embedding(17111, 10)\n",
       "  (rnn): LSTM(10, 15, batch_first=True)\n",
       "  (fc): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1010,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "id": "ba553382-faf0-40ad-8f38-dca38976ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "3272ce22-b6c5-4c55-ba8f-6c2361723cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating training loop\n",
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs=50):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for it in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "\n",
    "        epoch_losses = []\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader():\n",
    "            inputs = torch.from_numpy(inputs).to(device)\n",
    "            targets = torch.from_numpy(targets).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        train_losses.append(np.mean(epoch_losses))\n",
    "            \n",
    "        epoch_losses = []\n",
    "        model.eval()\n",
    "        for inputs, targets in test_loader():\n",
    "            inputs = torch.from_numpy(inputs).to(device)\n",
    "            targets = torch.from_numpy(targets).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        test_losses.append(np.mean(epoch_losses))\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "\n",
    "        print(f\"Epoch: {it+1}/{epochs}, Train Loss: {train_losses[it]}, Test Loss: {test_losses[it]}, Duration: {dt}\")\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "5c48f944-b03a-4d51-a41d-3aff29d66c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15, Train Loss: 0.6849175478730883, Test Loss: 0.6830279065503014, Duration: 0:00:00.489725\n",
      "Epoch: 2/15, Train Loss: 0.6807550092538198, Test Loss: 0.681388646364212, Duration: 0:00:00.467173\n",
      "Epoch: 3/15, Train Loss: 0.6780636778899601, Test Loss: 0.6783455477820503, Duration: 0:00:00.483277\n",
      "Epoch: 4/15, Train Loss: 0.672963715734936, Test Loss: 0.6744159493181441, Duration: 0:00:00.483186\n",
      "Epoch: 5/15, Train Loss: 0.6650157258624122, Test Loss: 0.667954706483417, Duration: 0:00:00.467664\n",
      "Epoch: 6/15, Train Loss: 0.6518661053407759, Test Loss: 0.6584391991297404, Duration: 0:00:00.480305\n",
      "Epoch: 7/15, Train Loss: 0.6314811337561834, Test Loss: 0.6447111997339461, Duration: 0:00:00.469516\n",
      "Epoch: 8/15, Train Loss: 0.602206601983025, Test Loss: 0.6288462844159868, Duration: 0:00:00.465531\n",
      "Epoch: 9/15, Train Loss: 0.5660978555679321, Test Loss: 0.6154881252182854, Duration: 0:00:00.528763\n",
      "Epoch: 10/15, Train Loss: 0.527130283060528, Test Loss: 0.6049738427003225, Duration: 0:00:00.487171\n",
      "Epoch: 11/15, Train Loss: 0.491047502273605, Test Loss: 0.5984029206964705, Duration: 0:00:00.496985\n",
      "Epoch: 12/15, Train Loss: 0.45674328931740354, Test Loss: 0.5976298020945655, Duration: 0:00:00.438734\n",
      "Epoch: 13/15, Train Loss: 0.4272452202581224, Test Loss: 0.6026108165582021, Duration: 0:00:00.466864\n",
      "Epoch: 14/15, Train Loss: 0.4025121693100248, Test Loss: 0.5968457758426666, Duration: 0:00:00.481611\n",
      "Epoch: 15/15, Train Loss: 0.38031265920116786, Test Loss: 0.5960533320903778, Duration: 0:00:00.456306\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "8d953d9c-e5f9-43a5-9cae-5436e545435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "8c842f42-1c28-4cc5-8b0a-1a2f550d4140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8583, Test Accuracy: 0.7084\n"
     ]
    }
   ],
   "source": [
    "## checking accuracy\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_num = 0\n",
    "    total = 0\n",
    "    for inputs, targets in train_loader():\n",
    "        inputs = torch.from_numpy(inputs).to(device)\n",
    "        targets = torch.from_numpy(targets).to(device)\n",
    "        preds = model(inputs)\n",
    "        preds = preds > 0\n",
    "        total += (preds == targets).sum().item()\n",
    "        sample_num += inputs.size(0)\n",
    "\n",
    "    train_acc = total/sample_num\n",
    "    \n",
    "    sample_num = 0\n",
    "    total = 0\n",
    "    for inputs, targets in test_loader():\n",
    "        inputs = torch.from_numpy(inputs).to(device)\n",
    "        targets = torch.from_numpy(targets).to(device)\n",
    "        preds = model(inputs)\n",
    "        preds = preds > 0\n",
    "        total += (preds == targets).sum().item()\n",
    "        sample_num += inputs.size(0)\n",
    "\n",
    "    test_acc = total/sample_num\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd288f-6147-402a-9102-03fa84e8e3cf",
   "metadata": {},
   "source": [
    "#### Prediction on submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "aaf2c4c7-a741-4233-bc2e-f2f4fc25c0fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [989]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_text \u001b[38;5;241m=\u001b[39m \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_text_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [989]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_text \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfull_text_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "Input \u001b[1;32mIn [972]\u001b[0m, in \u001b[0;36mfull_text_process\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     31\u001b[0m text \u001b[38;5;241m=\u001b[39m process_text(text)\n\u001b[0;32m     32\u001b[0m text \u001b[38;5;241m=\u001b[39m tokenize(text)\n\u001b[1;32m---> 33\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mremove_stopwords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "Input \u001b[1;32mIn [972]\u001b[0m, in \u001b[0;36mremove_stopwords\u001b[1;34m(token_list)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## test\n",
    "test_text = df_test[\"text\"].apply(lambda x: full_text_process(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7daba6-8ce0-4f71-abda-d7c5177ed8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting text token list to index list\n",
    "token_to_int(test_text, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9bd51b-52e4-4879-9b99-e3ed34712e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_loader = lambda: data_loader_no_target(test_text, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb7929-48de-494b-9daf-7d560cef14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds = np.array([])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs in submission_loader():\n",
    "        inputs = torch.from_numpy(inputs).to(device)\n",
    "        preds = model(inputs)\n",
    "        preds = preds > 0\n",
    "        preds = preds.numpy().astype(int).flatten()\n",
    "        sub_preds = np.concatenate([sub_preds, preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473f747-fcc2-4a76-9124-e8cc2417ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating submission dataframe\n",
    "ids = df_test[\"id\"].values\n",
    "\n",
    "sub_df = pd.DataFrame({\"id\": ids, \"target\": sub_preds.astype(int)})\n",
    "\n",
    "## saving as csv\n",
    "if not os.path.exists(\"x__submissions\"):\n",
    "    os.mkdir(\"x__submissions\")\n",
    "\n",
    "sub_df.to_csv(\"x__submissions/sub3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641c6df-b26f-403c-b86f-f6f57653902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a067dc4-c416-4a5c-88b1-38b0d8fb7541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
