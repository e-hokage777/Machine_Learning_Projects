{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe575ae-0b44-4989-8de8-bcab8459a5f5",
   "metadata": {},
   "source": [
    "# Computer Vision for License Plate Recognition\n",
    "The objective of this challenge is to make use of `object detection` and `image classification` to tell the values on the number plates (`Tunisian`) of a car from its image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c6e925-1219-453f-92b8-c39372f2414f",
   "metadata": {},
   "source": [
    "## Approach\n",
    "- create two models\n",
    "- one to detect license plates\n",
    "- another to detect and numbers in the license plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "572318d3-c549-47d7-9cf2-136241975a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## matrix and dataframe packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## image packages\n",
    "import PIL as pil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## deep learning packages\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as torch_transforms\n",
    "\n",
    "## utility packages\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462ff93-96ad-4309-bea2-0df1507c1952",
   "metadata": {},
   "source": [
    "### Preparing paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d3cd089-1cb6-42a2-8829-3fc0bf0d18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"x__data\"\n",
    "\n",
    "## images path\n",
    "detection_imgs_path = f\"{data_path}/license_plates_detection_train/license_plates_detection_train/\"\n",
    "recognition_imgs_path = f\"{data_path}/license_plates_recognition_train/license_plates_recognition_train/\"\n",
    "test_path = f\"{data_path}/text/text_private/\"\n",
    "\n",
    "## annotations path\n",
    "detection_annots = f\"{data_path}/license_plates_detection_train.csv\"\n",
    "recognition_annots = f\"{data_path}/license_plates_recognition_train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b84406-a16b-404e-a93c-e4b483d13436",
   "metadata": {},
   "source": [
    "### Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7061e33-393e-4b27-b57b-a83dd8f9b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionImagesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.annots = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.unique_imgs = self.annots[\"img_id\"].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annots)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.unique_imgs[idx]\n",
    "        image = pil.Image.open(f\"{self.img_dir}/{img_name}\").convert(\"RGB\")\n",
    "        boxes = self.annots[self.annots[\"img_id\"] == img_name][[\"xmin\",\"ymin\",\"xmax\",\"ymax\"]].values.astype(np.float32)\n",
    "        labels = torch.ones(boxes.shape[0], dtype=torch.int8)\n",
    "        target = {\"boxes\": torch.from_numpy(boxes),\n",
    "                  \"labels\": labels\n",
    "                 }\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return image, target\n",
    "    \n",
    "class RecognitionImagesDataset(torch.utils.data.Dataset):\n",
    "    pass\n",
    "    \n",
    "class TestImagesDataset(torch.utils.data.Dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80477e-deb7-49ac-a36b-c5476569d71d",
   "metadata": {},
   "source": [
    "### Instantiating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71eadfea-4a3b-4d3a-ac8d-4c41f2fd655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torch_transforms.compose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
